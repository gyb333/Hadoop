实时计算相关技术
	Strom / JStrom    Spark Streming       Flink     
	   实时性高           有延迟             实时性高 
	   吞吐量较低         吞吐量高            吞吐量高
	   只能实时计算        离线+实时          离线+实时
	   算子比较少          算子丰富           算子丰富
	   	没有				 机器学习            没有
	   	没有				 图计算              没有
	   	使用比较少		 非常火              一般

一个完整的生态是非常重要的，spark生态特别完善

收集数据：			Flume  					主动推送
消息中间件/消息队列：Kafka  供spark Streaming 拉取数据
实时计算			Spark Streaming  		聚合后的数据-> mysql 明细数据-> hbase
web系统



Kafka的一些概念
	Broker ： 安装Kafka服务的那台集群就是一个broker（broker的id要全局唯一）
	Producer ：消息的生产者，负责将数据写入到broker中（push）
	Consumer：消息的消费者，负责从kafka中读取数据（pull），老版本的消费者需要依赖zk，新版本的不需要
	Topic: 主题，相当于是数据的一个分类，不同topic存放不同的数据
	Consumer Group： 消费者组，一个topic可以有多个消费者同时消费，多个消费者如果在一个消费者组中，那么他们不能重复消费数据

Spark Streaming 2.2.0兼容kafka 0.8.2.1以上的版本，主要支持0.8和0.10这两个版本

---------------------------------------------------------
kafka集群安装
	1.下载Kafka安装包
	2.上传安装包
	3.解压
	4.修改配置文件 config/server.properties
		broker.id=0
		listeners=PLAINTEXT://Master:9092
		log.dirs=/usr/local/BigData/Kafka
		zookeeper.connect=Master:2181,Second:2181,Slave:2181
	5.将配置好的kafka拷贝到其他机器上
	6.修改broker.id和host.name
	7.启动kafka
		kafka-server-start.sh -daemon kafka2.11/config/server.properties


	#查看topic信息
	kafka-topics.sh --list --zookeeper Master:2181,Second:2181,Slave:2181

	#创建topic
	kafka-topics.sh --create --zookeeper Master:2181,Second:2181,Slave:2181 --replication-factor 3 --partitions 3 --topic my-topic

	#往Kafka的topic中写入数据(命令行的生成者)
	kafka-topics.sh --describe --zookeeper Master:2181,Second:2181,Slave:2181 --topic my-topic
	
	启动一个命令行的生产者:
	kafka-console-producer.sh --broker-list Master:9092,Second:9092,Slave:9092 --topic my-topic
	
	启动一个命令行的消费者:消费者连接到borker的地址
	kafka-console-consumer.sh --bootstrap-server Master:9092,Second:9092,Slave:9092 --topic my-topic --from-beginning 

	
	
	
	